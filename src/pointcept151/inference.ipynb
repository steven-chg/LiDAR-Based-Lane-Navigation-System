{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from pointcept.models.point_transformer_v3.point_transformer_v3m1_base import PointTransformerV3\n",
    "from pointcept.datasets.transform import (\n",
    "    GridSample, Compose, ToTensor, Collect, RandomRotateTargetAngle, TRANSFORMS\n",
    ")\n",
    "from pointcept.datasets.utils import collate_fn\n",
    "from collections import OrderedDict\n",
    "import pointcept.utils.comm as comm\n",
    "from pointcept.models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(points, weight_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        points: numpy array of shape (n,4) - x,y,z,intensity\n",
    "        weight_path: path to model weights\n",
    "    Returns:\n",
    "        pred: predictions\n",
    "        probs: confidence scores\n",
    "    \"\"\"\n",
    "    # Create data dict \n",
    "    coord = points[:, :3]\n",
    "    strength = points[:, -1].reshape([-1, 1])\n",
    "    segment = np.zeros(points.shape[0]).astype(np.int32)\n",
    "    data_dict = dict(coord=coord, strength=strength, segment=segment)\n",
    "\n",
    "    # Define model config directly\n",
    "    model_cfg = dict(\n",
    "        type='DefaultSegmentorV2',\n",
    "        num_classes=2,\n",
    "        backbone_out_channels=64,\n",
    "        backbone=dict(\n",
    "            type='PT-v3m1',\n",
    "            in_channels=4,\n",
    "            order=['z', 'z-trans', 'hilbert', 'hilbert-trans'],\n",
    "            stride=(2, 2, 2, 2),\n",
    "            enc_depths=(2, 2, 2, 6, 2),\n",
    "            enc_channels=(32, 64, 128, 256, 512),\n",
    "            enc_num_head=(2, 4, 8, 16, 32),\n",
    "            enc_patch_size=(64, 64, 64, 64, 64),\n",
    "            dec_depths=(2, 2, 2, 2),\n",
    "            dec_channels=(64, 64, 128, 256),\n",
    "            dec_num_head=(4, 4, 8, 16),\n",
    "            dec_patch_size=(64, 64, 64, 64),\n",
    "            mlp_ratio=4,\n",
    "            qkv_bias=True,\n",
    "            qk_scale=None,\n",
    "            attn_drop=0.0,\n",
    "            proj_drop=0.0,\n",
    "            drop_path=0.3,\n",
    "            shuffle_orders=True,\n",
    "            pre_norm=True,\n",
    "            enable_rpe=False,\n",
    "            enable_flash=False,\n",
    "            upcast_attention=False,\n",
    "            upcast_softmax=False,\n",
    "            cls_mode=False,\n",
    "            pdnorm_bn=False,\n",
    "            pdnorm_ln=False,\n",
    "            pdnorm_decouple=True,\n",
    "            pdnorm_adaptive=False,\n",
    "            pdnorm_affine=True,\n",
    "            pdnorm_conditions=('nuScenes', 'SemanticKITTI', 'Waymo'))\n",
    "    )\n",
    "\n",
    "    # Initialize model and load weights\n",
    "    model = build_model(model_cfg)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        checkpoint = torch.load(weight_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(weight_path, map_location='cpu')\n",
    "        \n",
    "    # Load state dict\n",
    "    weight = OrderedDict()\n",
    "    for key, value in checkpoint[\"state_dict\"].items():\n",
    "        if key.startswith(\"module.\"):\n",
    "            key = key[7:]\n",
    "        weight[key] = value\n",
    "    model.load_state_dict(weight, strict=True)\n",
    "    model.eval()\n",
    "\n",
    "    # Define and apply transforms\n",
    "    transform = Compose([\n",
    "        dict(type='Copy', keys_dict=dict(segment='origin_segment')),\n",
    "        dict(\n",
    "            type='GridSample',\n",
    "            grid_size=0.025,\n",
    "            hash_type='fnv',\n",
    "            mode='train',\n",
    "            keys=('coord', 'strength', 'segment'),\n",
    "            return_inverse=True)\n",
    "    ])\n",
    "    data_dict = transform(data_dict)\n",
    "    inverse = data_dict.pop(\"inverse\")\n",
    "\n",
    "    # Apply voxelize transform\n",
    "    voxelize = TRANSFORMS.build(dict(\n",
    "        type='GridSample',\n",
    "        grid_size=0.05,\n",
    "        hash_type='fnv',\n",
    "        mode='test',\n",
    "        return_grid_coord=True,\n",
    "        keys=('coord', 'strength')))\n",
    "    data_part_list = voxelize(data_dict)\n",
    "\n",
    "    # Apply post transform\n",
    "    post_transform = Compose([\n",
    "        dict(type='ToTensor'),\n",
    "        dict(\n",
    "            type='Collect',\n",
    "            keys=('coord', 'grid_coord', 'index'),\n",
    "            feat_keys=('coord', 'strength'))\n",
    "    ])\n",
    "    \n",
    "    fragment_list = []\n",
    "    for data_part in data_part_list:\n",
    "        fragment_list.append(post_transform(data_part))\n",
    "\n",
    "    # Do inference\n",
    "    pred = torch.zeros((points.shape[0], 2))  # num_classes = 2\n",
    "    if torch.cuda.is_available():\n",
    "        pred = pred.cuda()\n",
    "\n",
    "    for fragment in fragment_list:\n",
    "        idx_part = fragment[\"index\"]\n",
    "        \n",
    "        input_dict = {}\n",
    "        for key, value in fragment.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                input_dict[key] = value.cuda() if torch.cuda.is_available() else value\n",
    "            else:\n",
    "                input_dict[key] = value\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_part = model(input_dict)[\"seg_logits\"]\n",
    "            pred_part = F.softmax(pred_part, -1)\n",
    "            \n",
    "            bs = 0\n",
    "            for be in input_dict[\"offset\"]:\n",
    "                pred[idx_part[bs:be], :] += pred_part[bs:be]\n",
    "                bs = be\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Get final predictions and probabilities \n",
    "    probs = pred.max(1)[0].cpu().numpy()\n",
    "    pred = pred.max(1)[1].cpu().numpy()\n",
    "\n",
    "    # Map back to original points\n",
    "    pred = pred[inverse]\n",
    "    probs = probs[inverse]\n",
    "\n",
    "    return pred, probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/yan/pointcept151/dataset/sequences/00/velodyne/000200.bin'\n",
    "#read the point cloud data\n",
    "def read_bin(path):\n",
    "    pc = np.fromfile(path, dtype=np.float32).reshape(-1, 4)\n",
    "    return pc\n",
    "test_points = read_bin(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "points = np.random.rand(1000, 4)\n",
    "# Load pointcloud\n",
    "# points = np.fromfile(points_in, dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "weight_path=\"/home/yan/pointcept151/exp/nuscenes/train_highbay_02/model/model_best.pth\"\n",
    "# Run inference\n",
    "pred, probs = inference(test_points, weight_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred,return_counts=True)\n",
    "np.save('pred.npy',pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
