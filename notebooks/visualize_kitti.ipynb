{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pptk\n",
    "import os\n",
    "\n",
    "def load_points(bin_path):\n",
    "    \"\"\"Load point cloud from .bin file\"\"\"\n",
    "    points = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4)\n",
    "    return points\n",
    "\n",
    "def load_labels(label_path):\n",
    "    \"\"\"Load semantic labels\"\"\"\n",
    "    labels = np.fromfile(label_path, dtype=np.int32)\n",
    "    # Semantic labels are in the lower 16 bits\n",
    "    labels = labels & 0xFFFF\n",
    "    return labels\n",
    "\n",
    "def get_color_map():\n",
    "    \"\"\"Define color map for visualization\"\"\"\n",
    "    color_map = {\n",
    "        0: [0, 0, 0],        # unlabeled - black\n",
    "        1: [245, 150, 100],  # car - orange\n",
    "        2: [245, 230, 100],  # bicycle - yellow\n",
    "        3: [150, 60, 30],    # motorcycle - brown\n",
    "        4: [180, 30, 80],    # truck - dark red\n",
    "        5: [255, 0, 0],      # other-vehicle - red\n",
    "        6: [30, 30, 255],    # person - blue\n",
    "        7: [200, 40, 255],   # bicyclist - purple\n",
    "        8: [90, 30, 150],    # motorcyclist - dark purple\n",
    "        9: [255, 0, 255],    # road - magenta\n",
    "        10: [255, 150, 255], # parking - light magenta\n",
    "        11: [75, 0, 75],     # sidewalk - dark purple\n",
    "        12: [75, 0, 175],    # other-ground - purple\n",
    "        13: [0, 200, 255],   # building - light blue\n",
    "        14: [50, 120, 255],  # fence - blue\n",
    "        15: [0, 175, 0],     # vegetation - green\n",
    "        16: [0, 60, 135],    # trunk - dark blue\n",
    "        17: [80, 240, 150],  # terrain - light green\n",
    "        18: [150, 240, 255], # pole - light blue\n",
    "        19: [0, 0, 255]      # traffic-sign - blue\n",
    "    }\n",
    "    return color_map\n",
    "\n",
    "def visualize_frame(sequence_path, frame_number):\n",
    "    \"\"\"Visualize a single frame with labels and intensity\"\"\"\n",
    "    # Construct file paths\n",
    "    points_file = os.path.join(sequence_path, 'velodyne', f'{frame_number:06d}.bin')\n",
    "    labels_file = os.path.join(sequence_path, 'PRE', f'{frame_number:06d}.label')\n",
    "    \n",
    "    # Load point cloud and labels\n",
    "    points = load_points(points_file)\n",
    "    labels = load_labels(labels_file)\n",
    "    \n",
    "    # Get color map\n",
    "    color_map = get_color_map()\n",
    "    \n",
    "    # Convert labels to colors\n",
    "    colors = np.zeros((len(labels), 3))\n",
    "    for label_id, color in color_map.items():\n",
    "        mask = labels == label_id\n",
    "        colors[mask] = np.array(color) / 255.0\n",
    "    \n",
    "    # Extract intensity values (fourth column of points array)\n",
    "    intensities = points[:, 3]\n",
    "    \n",
    "    # Normalize intensities to [0, 1] range for better visualization\n",
    "    intensities_normalized = (intensities - intensities.min()) / (intensities.max() - intensities.min())\n",
    "    \n",
    "    # Visualize using pptk\n",
    "    v = pptk.viewer(points[:, :3])  # Only use x, y, z coordinates\n",
    "    \n",
    "    # Set both colors and intensities as attributes\n",
    "    # You can switch between them using 'a' key in the viewer\n",
    "    v.attributes(colors, intensities_normalized)\n",
    "    v.set(point_size=0.02)\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\484_final_project\\\\dataset\\\\sequences\\\\00\\\\PRE\\\\000200.label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24432\\764496169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Visualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvisualize_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24432\\3643557708.py\u001b[0m in \u001b[0;36mvisualize_frame\u001b[1;34m(sequence_path, frame_number)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Load point cloud and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# Get color map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24432\\3643557708.py\u001b[0m in \u001b[0;36mload_labels\u001b[1;34m(label_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;34m\"\"\"Load semantic labels\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Semantic labels are in the lower 16 bits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFFFF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\484_final_project\\\\dataset\\\\sequences\\\\00\\\\PRE\\\\000200.label'"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "base_path = r\"D:\\484_final_project\\dataset\"  # Change this to your dataset path\n",
    "sequence = \"00\"  # Change this to visualize different sequences\n",
    "frame = 200       # Change this to visualize different frames\n",
    "\n",
    "sequence_path = os.path.join(base_path, 'sequences', sequence)\n",
    "\n",
    "# Visualize\n",
    "viewer = visualize_frame(sequence_path, frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pptk\n",
    "import os\n",
    "\n",
    "def load_points(bin_path):\n",
    "    \"\"\"Load point cloud from .bin file\"\"\"\n",
    "    points = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4)\n",
    "    return points\n",
    "\n",
    "def load_labels(label_path):\n",
    "    \"\"\"Load semantic labels\"\"\"\n",
    "    labels = np.fromfile(label_path, dtype=np.int32)\n",
    "    # Semantic labels are in the lower 16 bits\n",
    "    labels = labels & 0xFFFF\n",
    "    return labels\n",
    "\n",
    "def get_color_map():\n",
    "    \"\"\"Define color map for visualization\"\"\"\n",
    "    color_map = {\n",
    "        0: [0, 0, 0],        # unlabeled - black\n",
    "        1: [245, 150, 100],  # car - orange\n",
    "        2: [245, 230, 100],  # bicycle - yellow\n",
    "        3: [150, 60, 30],    # motorcycle - brown\n",
    "        4: [180, 30, 80],    # truck - dark red\n",
    "        5: [255, 0, 0],      # other-vehicle - red\n",
    "        6: [30, 30, 255],    # person - blue\n",
    "        7: [200, 40, 255],   # bicyclist - purple\n",
    "        8: [90, 30, 150],    # motorcyclist - dark purple\n",
    "        9: [255, 0, 255],    # road - magenta\n",
    "        10: [255, 150, 255], # parking - light magenta\n",
    "        11: [75, 0, 75],     # sidewalk - dark purple\n",
    "        12: [75, 0, 175],    # other-ground - purple\n",
    "        13: [0, 200, 255],   # building - light blue\n",
    "        14: [50, 120, 255],  # fence - blue\n",
    "        15: [0, 175, 0],     # vegetation - green\n",
    "        16: [0, 60, 135],    # trunk - dark blue\n",
    "        17: [80, 240, 150],  # terrain - light green\n",
    "        18: [150, 240, 255], # pole - light blue\n",
    "        19: [0, 0, 255]      # traffic-sign - blue\n",
    "    }\n",
    "    return color_map\n",
    "\n",
    "def visualize_frame_range(sequence_path, start_frame, end_frame, frame_step=1):\n",
    "    \"\"\"\n",
    "    Visualize multiple frames together\n",
    "    \n",
    "    Args:\n",
    "        sequence_path (str): Path to the sequence directory\n",
    "        start_frame (int): Starting frame number\n",
    "        end_frame (int): Ending frame number (inclusive)\n",
    "        frame_step (int): Step size between frames (default=1)\n",
    "    \n",
    "    Returns:\n",
    "        pptk.viewer: Viewer object\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "    all_labels = []\n",
    "    frame_offsets = []  # Store frame-specific offsets for visualization\n",
    "    \n",
    "    # Load and combine all frames\n",
    "    for frame_number in range(start_frame, end_frame + 1, frame_step):\n",
    "        # Construct file paths\n",
    "        points_file = os.path.join(sequence_path, 'velodyne', f'{frame_number:06d}.bin')\n",
    "        labels_file = os.path.join(sequence_path, 'predictions', f'{frame_number:06d}.label')\n",
    "        \n",
    "        if not (os.path.exists(points_file) and os.path.exists(labels_file)):\n",
    "            print(f\"Skipping frame {frame_number} - files not found\")\n",
    "            continue\n",
    "            \n",
    "        # Load point cloud and labels\n",
    "        points = load_points(points_file)\n",
    "        labels = load_labels(labels_file)\n",
    "        \n",
    "        # Add frame-specific offset to x coordinates to separate frames\n",
    "        frame_offset = len(frame_offsets) * 5.0  # 5 meters between frames\n",
    "        points_offset = points.copy()\n",
    "        points_offset[:, 0] += frame_offset  # Offset x coordinates\n",
    "        \n",
    "        all_points.append(points_offset)\n",
    "        all_labels.append(labels)\n",
    "        frame_offsets.append(frame_offset)\n",
    "    \n",
    "    if not all_points:\n",
    "        raise ValueError(\"No valid frames found in the specified range\")\n",
    "    \n",
    "    # Combine all points and labels\n",
    "    combined_points = np.vstack(all_points)\n",
    "    combined_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # Get color map and convert labels to colors\n",
    "    color_map = get_color_map()\n",
    "    colors = np.zeros((len(combined_labels), 3))\n",
    "    for label_id, color in color_map.items():\n",
    "        mask = combined_labels == label_id\n",
    "        colors[mask] = np.array(color) / 255.0\n",
    "    \n",
    "    # Extract and normalize intensities\n",
    "    intensities = combined_points[:, 3]\n",
    "    intensities_normalized = (intensities - intensities.min()) / (intensities.max() - intensities.min())\n",
    "    \n",
    "    # Create viewer\n",
    "    v = pptk.viewer(combined_points[:, :3])\n",
    "    v.attributes(colors, intensities_normalized)\n",
    "    v.set(point_size=0.02)\n",
    "    \n",
    "    # Set a better view point to see all frames\n",
    "    center_point = combined_points[:, :3].mean(axis=0)\n",
    "    v.set(lookat=center_point)\n",
    "    \n",
    "    # Print information about visualization\n",
    "    print(f\"Visualizing {len(frame_offsets)} frames from {start_frame} to {end_frame}\")\n",
    "    print(\"Use 'a' key to switch between color and intensity visualization\")\n",
    "    print(\"Use mouse to rotate/pan/zoom the view\")\n",
    "    \n",
    "    return v\n",
    "\n",
    "def visualize_frame_list(sequence_path, frame_numbers):\n",
    "    \"\"\"\n",
    "    Visualize specific frames by their numbers\n",
    "    \n",
    "    Args:\n",
    "        sequence_path (str): Path to the sequence directory\n",
    "        frame_numbers (list): List of frame numbers to visualize\n",
    "    \n",
    "    Returns:\n",
    "        pptk.viewer: Viewer object\n",
    "    \"\"\"\n",
    "    if not frame_numbers:\n",
    "        raise ValueError(\"Frame numbers list is empty\")\n",
    "    \n",
    "    start_frame = min(frame_numbers)\n",
    "    end_frame = max(frame_numbers)\n",
    "    \n",
    "    def custom_frame_filter(frame):\n",
    "        return frame in frame_numbers\n",
    "    \n",
    "    # Use visualize_frame_range with step=1 and skip unwanted frames\n",
    "    all_points = []\n",
    "    all_labels = []\n",
    "    frame_offsets = []\n",
    "    \n",
    "    for frame_number in range(start_frame, end_frame + 1):\n",
    "        if not custom_frame_filter(frame_number):\n",
    "            continue\n",
    "            \n",
    "        points_file = os.path.join(sequence_path, 'velodyne', f'{frame_number:06d}.bin')\n",
    "        labels_file = os.path.join(sequence_path, 'predictions', f'{frame_number:06d}.label')\n",
    "        \n",
    "        if not (os.path.exists(points_file) and os.path.exists(labels_file)):\n",
    "            print(f\"Skipping frame {frame_number} - files not found\")\n",
    "            continue\n",
    "        \n",
    "        points = load_points(points_file)\n",
    "        labels = load_labels(labels_file)\n",
    "        \n",
    "        frame_offset = len(frame_offsets) * 5.0\n",
    "        points_offset = points.copy()\n",
    "        points_offset[:, 0] += frame_offset\n",
    "        \n",
    "        all_points.append(points_offset)\n",
    "        all_labels.append(labels)\n",
    "        frame_offsets.append(frame_offset)\n",
    "    \n",
    "    if not all_points:\n",
    "        raise ValueError(\"No valid frames found in the specified list\")\n",
    "    \n",
    "    combined_points = np.vstack(all_points)\n",
    "    combined_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    color_map = get_color_map()\n",
    "    colors = np.zeros((len(combined_labels), 3))\n",
    "    for label_id, color in color_map.items():\n",
    "        mask = combined_labels == label_id\n",
    "        colors[mask] = np.array(color) / 255.0\n",
    "    \n",
    "    intensities = combined_points[:, 3]\n",
    "    intensities_normalized = (intensities - intensities.min()) / (intensities.max() - intensities.min())\n",
    "    \n",
    "    v = pptk.viewer(combined_points[:, :3])\n",
    "    v.attributes(colors, intensities_normalized)\n",
    "    v.set(point_size=0.02)\n",
    "    \n",
    "    center_point = combined_points[:, :3].mean(axis=0)\n",
    "    v.set(lookat=center_point)\n",
    "    \n",
    "    print(f\"Visualizing {len(frame_offsets)} frames: {sorted(frame_numbers)}\")\n",
    "    print(\"Use 'a' key to switch between color and intensity visualization\")\n",
    "    print(\"Use mouse to rotate/pan/zoom the view\")\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 767 frames\n",
      "Output shape: (767, 131072)\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "base_path = r\"D:\\484_final_project\\dataset\"  # Change this to your dataset path\n",
    "sequence = \"00\"  # Change this to visualize different sequences\n",
    "\n",
    "sequence_path = os.path.join(base_path, 'sequences', sequence)\n",
    "\n",
    "# Visualize\n",
    "# v1 = visualize_frame_range(sequence_path, 0, 5)\n",
    "predictions, frame_nums = concatenate_predictions(\n",
    "    sequence_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 131072)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('slam03_predictions_01.npy',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def concatenate_predictions(sequence_path):\n",
    "    \"\"\"\n",
    "    Concatenate all prediction labels into a single numpy array.\n",
    "    \n",
    "    Args:\n",
    "        sequence_path (str): Path to the sequence directory containing 'predictions' folder\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Concatenated predictions with shape (num_frames)\n",
    "        list: List of frame numbers that were processed\n",
    "    \"\"\"\n",
    "    # Get all prediction files\n",
    "    pred_path = os.path.join(sequence_path, 'predictions_grid_01')\n",
    "    pred_files = glob(os.path.join(pred_path, '*.label'))\n",
    "    pred_files.sort()  # Ensure files are in order\n",
    "    \n",
    "    num_frames = len(pred_files)\n",
    "    if num_frames == 0:\n",
    "        raise ValueError(f\"No prediction files found in {pred_path}\")\n",
    "    \n",
    "    # List to store all predictions\n",
    "    all_predictions = []\n",
    "    frame_numbers = []\n",
    "    \n",
    "    for pred_file in pred_files:\n",
    "        # Extract frame number from filename\n",
    "        frame_num = int(os.path.basename(pred_file).split('.')[0])\n",
    "        frame_numbers.append(frame_num)\n",
    "        \n",
    "        try:\n",
    "            # Load labels\n",
    "            labels = np.fromfile(pred_file, dtype=np.int32)\n",
    "            labels = labels & 0xFFFF  # Get semantic labels from lower 16 bits\n",
    "            all_predictions.append(labels)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {frame_num}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Stack all predictions\n",
    "    predictions = np.stack(all_predictions)\n",
    "    \n",
    "    print(f\"Processed {len(frame_numbers)} frames\")\n",
    "    print(f\"Output shape: {predictions.shape}\")\n",
    "    \n",
    "    return predictions, frame_numbers\n",
    "\n",
    "def save_concatenated_predictions(sequence_path, output_path):\n",
    "    \"\"\"\n",
    "    Concatenate predictions and save to a numpy file.\n",
    "    \n",
    "    Args:\n",
    "        sequence_path (str): Path to the sequence directory\n",
    "        output_path (str): Path to save the concatenated predictions\n",
    "    \"\"\"\n",
    "    predictions, frame_numbers = concatenate_predictions(sequence_path)\n",
    "    \n",
    "    # Save both predictions and frame numbers\n",
    "    np.savez_compressed(\n",
    "        output_path,\n",
    "        predictions=predictions,\n",
    "        frame_numbers=frame_numbers\n",
    "    )\n",
    "    print(f\"Saved concatenated predictions to {output_path}\")\n",
    "    \n",
    "def load_concatenated_predictions(file_path):\n",
    "    \"\"\"\n",
    "    Load previously saved concatenated predictions.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the saved .npz file\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (predictions array, frame numbers list)\n",
    "    \"\"\"\n",
    "    data = np.load(file_path)\n",
    "    return data['predictions'], data['frame_numbers'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
